{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## r/AmItheAsshole Lanugage Analysis\n",
    "\n",
    "### Introduction\n",
    "\n",
    "[r/AmItheAsshole](https://www.reddit.com/r/AmItheAsshole/) is a subreddit where people will post a story about some conflict they've had and it is up to the community to judge who the \"asshole\" is in the situation. The page description words this very eloquently:\n",
    "\n",
    "\"A catharsis for the frustrated moral philosopher in all of us, and a place to finally find out if you were wrong in an argument that's been bothering you. Tell us about any non-violent conflict you have experienced; give us both sides of the story, and find out if you're right, or you're the asshole.\" ([r/AmItheAsshole](https://www.reddit.com/r/AmItheAsshole/))\n",
    "\n",
    "The goal of this project if there are any notable lexical features between the langauge of the \"assholes\" and those who are not.\n",
    "\n",
    "One thing that I would like to note is that this is not a corpus directly translated from speech so the language of the mosts might have been thoughfully worded and might not be representative of ones's natural speech. Still I believe that the judgments voted on by the reddit community can provide insight on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping from Reddit\n",
    "#### PRAW\n",
    "[The Python Reddit API Wrapper (PRAW)](https://praw.readthedocs.io/en/v4.1.0/index.html) is an API for anything you can do in Reddit. In this project it is used to scrape posts from the r/AmItheAsshole subreddit.\n",
    "\n",
    "#### The r/AmItheAsshole Archives\n",
    "The subreddit archives the posts into 4 different categories related to this project. There are 5 judgements that one can decide on, however the last one that is not archived 'INFO' (Not enough info) does not help with this investigation. The different judgements are described in the function below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions for scraping from reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import yaml\n",
    "import praw\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "\n",
    "\n",
    "# Initialize reddit API\n",
    "reddit = praw.Reddit('scraper', user_agent='corpus ling project')\n",
    "reddit.read_only = True\n",
    "\n",
    "# Abbreviations for the archive queries\n",
    "archive_names = { 'YTA' : 'Asshole', 'NTA' : 'Not the A-hole', 'ESH' : 'Everyone Sucks',\n",
    "        'NAH' : 'No A-holes here'}\n",
    "\n",
    "# Pandas dataframe containing all of the posts.\n",
    "corpus = pd.DataFrame()\n",
    "\n",
    "def get_archive(judgment):\n",
    "    '''\n",
    "    Get the posts from a single archive of r/AmItheAsshole\n",
    "    Archive judgement options are:\n",
    "        'YTA' -- You're the Asshole (& the other party is not)\n",
    "        'NTA' -- You're Not the A-hole (& the other party is)\n",
    "        'ESH' -- Everyone Sucks Here\n",
    "        'NAH' -- No A-holes here\n",
    "    '''\n",
    "    return reddit.subreddit('AmItheAsshole').search(\n",
    "            'flair_name:\"' + archive_names[judgment] + '\"', limit=None)\n",
    "\n",
    "def load_archives(download_local = True):\n",
    "    '''\n",
    "    Grabs each of the archives and puts them in the corpus dictionary.\n",
    "    The download_local flag determines if you want to download the text\n",
    "    as well in the current directory.\n",
    "    '''\n",
    "    global corpus \n",
    "    corpus = pd.DataFrame()\n",
    "    for judgement in tqdm_notebook(archive_names.keys()):\n",
    "        posts = get_archive(judgement)\n",
    "        row_df = pd.io.json.json_normalize(\n",
    "                map(lambda post : {'archive' : judgement, **vars(post)}, posts))\n",
    "        # store only the id, title, archive, rawtext, and url\n",
    "        corpus = corpus.append(row_df[['id', 'title', 'archive', 'selftext', 'url']],\n",
    "                               ignore_index = True, sort=True)        \n",
    "        \n",
    "        # Download the text locally\n",
    "        if (download_local):\n",
    "            if not os.path.exists(judgement):\n",
    "                # separate archives into different directories.\n",
    "                os.mkdir(judgement)\n",
    "            for index, post in (corpus.loc[corpus['archive'] == judgement]).iterrows():\n",
    "                # Save each file in their respective directories with their id as the filename\n",
    "                with open(judgement + '/' + post.id + '.yaml', 'w') as file:\n",
    "                    documents = yaml.dump(post.to_dict(), file)\n",
    "\n",
    "def local_load_archives():\n",
    "    '''\n",
    "    Loads the archived posts from yaml files in the current directory.\n",
    "    '''\n",
    "    global corpus \n",
    "    corpus = pd.DataFrame()\n",
    "    for judgement in tqdm_notebook(archive_names.keys()):\n",
    "        for filename in glob.glob(judgement + '/*.yaml'):\n",
    "            with open(filename) as file:\n",
    "                corpus = corpus.append(pd.io.json.json_normalize(\n",
    "                    yaml.load(file, Loader=yaml.FullLoader)),\n",
    "                                       ignore_index = True, sort=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Several options for loading the corpus of posts:\n",
    "To keep things consistent, please use the `local_load_archives()` option becuase posts might be added over time and so the anaysis of this corpus may change as new posts are added.\n",
    "\n",
    "Note: `load_archives()` will not work unless you have a `praw.ini` file in the current directory. This file contains the necesary account information for using the Reddit API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you just want to use the posts that are downloaded locally.\n",
    "local_load_archives()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you want the most recent set of posts but without downloading them locally.\n",
    "load_archives(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you want to load and update the local files with the current archives.\n",
    "load_archives()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The corpus\n",
    "The corpus of posts is represented as a datarame whos most important columns are the archive column, and the text. The following code prints out summaries of all of the archives with the counts of posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Summary of all of the posts in the \"Asshole\" archive:\n",
      "       archive      id                                           selftext  \\\n",
      "count      238     238                                                238   \n",
      "unique       1     238                                                238   \n",
      "top        YTA  e8qq4s  I had my daughter young, her father stood by m...   \n",
      "freq       238       1                                                  1   \n",
      "\n",
      "                                                    title  \\\n",
      "count                                                 238   \n",
      "unique                                                238   \n",
      "top     AITA for not wanting to cancel our vacation pl...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                                      url  \n",
      "count                                                 238  \n",
      "unique                                                238  \n",
      "top     https://www.reddit.com/r/AmItheAsshole/comment...  \n",
      "freq                                                    1  \n",
      "\n",
      "\n",
      " Summary of all of the posts in the \"Not the A-hole\" archive:\n",
      "       archive      id                                           selftext  \\\n",
      "count      228     228                                                228   \n",
      "unique       1     228                                                228   \n",
      "top        NTA  eabsc6  I (F 22) work part time at my father’s restaur...   \n",
      "freq       228       1                                                  1   \n",
      "\n",
      "                                                    title  \\\n",
      "count                                                 228   \n",
      "unique                                                228   \n",
      "top     AITA for returning the neighbours passive aggr...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                                      url  \n",
      "count                                                 228  \n",
      "unique                                                228  \n",
      "top     https://www.reddit.com/r/AmItheAsshole/comment...  \n",
      "freq                                                    1  \n",
      "\n",
      "\n",
      " Summary of all of the posts in the \"Everyone Sucks\" archive:\n",
      "       archive      id                                           selftext  \\\n",
      "count      234     234                                                234   \n",
      "unique       1     234                                                234   \n",
      "top        ESH  e6vxh8  My ex-wife and I have been divorced for almost...   \n",
      "freq       234       1                                                  1   \n",
      "\n",
      "                                                    title  \\\n",
      "count                                                 234   \n",
      "unique                                                234   \n",
      "top     AITA for calling my GF profanities so she stop...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                                      url  \n",
      "count                                                 234  \n",
      "unique                                                234  \n",
      "top     https://www.reddit.com/r/AmItheAsshole/comment...  \n",
      "freq                                                    1  \n",
      "\n",
      "\n",
      " Summary of all of the posts in the \"No A-holes here\" archive:\n",
      "       archive      id                                           selftext  \\\n",
      "count      240     240                                                240   \n",
      "unique       1     240                                                240   \n",
      "top        NAH  e4rk7x  As of late, my mother hasn’t been 100% there a...   \n",
      "freq       240       1                                                  1   \n",
      "\n",
      "                                                    title  \\\n",
      "count                                                 240   \n",
      "unique                                                240   \n",
      "top     AITA for not eating any of my moms home cooked...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                                      url  \n",
      "count                                                 240  \n",
      "unique                                                240  \n",
      "top     https://www.reddit.com/r/AmItheAsshole/comment...  \n",
      "freq                                                    1  \n"
     ]
    }
   ],
   "source": [
    "for judgement in archive_names.keys():\n",
    "    print(\"\\n\\n Summary of all of the posts in the \\\"\" + archive_names[judgement] + \"\\\" archive:\")\n",
    "    print(corpus.loc[corpus['archive'] == judgement].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feel free to take a break and read a random post:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "My wife and I are on vacation in Orlando Florida and needed a ride to Denny’s. I ordered the UBER and was matched with a man that arrived in less than 2 minutes after we requested. When we sat down in the car he looked back and asked if he could use the bathroom really fast, and we said it was fine. Me and my wife looked at each other and agreed that it’s fair that someone should be allowed to use the bathroom if need be (obviously). He actually did a slow jog into the resort we were staying at, turned around and returned to tell us the rate wouldn’t go up because of it. But as time went on I told my wife there was no way I’m giving this guy 5 stars, she thinks it’s not fair to the driver. The entire affair lasted 5 minutes or so. Why wouldn’t he use the bathroom before he accepted the ride? I hate rating Uber drivers with low scores because it’s their livelyhood but come on dude. AITA?\n",
      "\n",
      "TDLR\n",
      "Friendly Uber driver picked my wife and I up and then left us in the car to use the bathroom.\n"
     ]
    }
   ],
   "source": [
    "post = corpus.sample(n=1)\n",
    "print(post.selftext.tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Can you guess how the community judged this submission?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asshole\n"
     ]
    }
   ],
   "source": [
    "print(archive_names[post.archive.tolist()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Corpus\n",
    "#### NLTK\n",
    "[Natural Language Toolkit (NLTK)](https://www.nltk.org/) is a python library with a lot of Natural Language processing tools.\n",
    "\n",
    "First we need to import nltk and download some tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions for using the nltk library on the corpus dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize, Text, FreqDist\n",
    "\n",
    "def corpus_tokenize():\n",
    "    '''\n",
    "    Converts the text of each post to a list of tokens and places\n",
    "    them in a list in a column within the corpus dataframe.\n",
    "    '''\n",
    "    global corpus\n",
    "    corpus['tokens'] = list(map(lambda text : word_tokenize(text.lower()), corpus['selftext']))\n",
    "    # Get rid of punctuation\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    corpus['tokens_no_punct'] = list(map(lambda text : tokenizer.tokenize(text.lower()), corpus['selftext']))\n",
    "    # Tokenize on sentences.\n",
    "    corpus['sent_tokens'] = list(map(sent_tokenize, corpus['selftext']))\n",
    "    \n",
    "def get_archive_texts(archives, no_punctuation = False):\n",
    "    '''\n",
    "    Gets the texts of every post of the archives listed in archives\n",
    "    and returns it as one list of words.\n",
    "    '''\n",
    "    global corpus\n",
    "    texts = []\n",
    "    for archive in archives:\n",
    "        for post_tokens in corpus.loc[corpus['archive'] == archive]['tokens_no_punct' if no_punctuation else 'tokens'].to_list():\n",
    "            texts += post_tokens\n",
    "    return texts\n",
    "\n",
    "def get_archive_texts_sentences(archives):\n",
    "    '''\n",
    "    Gets the texts of every post of the archives listed in archives\n",
    "    and returns it as one list of sentences.\n",
    "    '''\n",
    "    global corpus\n",
    "    texts = []\n",
    "    for archive in archives:\n",
    "        for sent_tokens in corpus.loc[corpus['archive'] == archive]['sent_tokens'].to_list():\n",
    "            texts += sent_tokens\n",
    "    return texts\n",
    "\n",
    "def get_freq_dist(archives, no_stopwords = False):\n",
    "    '''\n",
    "    Get a FreqDist for the given archive names There is also the option to remove stopwords.\n",
    "    '''\n",
    "    text = get_archive_texts(archives, no_punctuation=True)\n",
    "    if no_stopwords:\n",
    "        # filter out stopwords\n",
    "        stopwords = nltk.corpus.stopwords.words('english')\n",
    "        text = list(filter(lambda word : not word in stopwords, text))\n",
    "    return FreqDist(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the Corpus\n",
    "Creates three new columns in the corpus dataframe, 'tokens', 'tokens_no_punct', and 'sent_tokens'. One with just the raw output of the nltk tokenize function, the next without punctiation, and finally the text separated by sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>archive</th>\n",
       "      <th>id</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_no_punct</th>\n",
       "      <th>sent_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YTA</td>\n",
       "      <td>birkjn</td>\n",
       "      <td>My wife is pregnant with our daughter. Initial...</td>\n",
       "      <td>WIBTA if I ask my pregnant wife to move out be...</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>[my, wife, is, pregnant, with, our, daughter, ...</td>\n",
       "      <td>[my, wife, is, pregnant, with, our, daughter, ...</td>\n",
       "      <td>[My wife is pregnant with our daughter., Initi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YTA</td>\n",
       "      <td>d6cpjt</td>\n",
       "      <td>When my girlfriend and I put out advertisement...</td>\n",
       "      <td>AITA for throwing out my roommates non-vegan f...</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>[when, my, girlfriend, and, i, put, out, adver...</td>\n",
       "      <td>[when, my, girlfriend, and, i, put, out, adver...</td>\n",
       "      <td>[When my girlfriend and I put out advertisemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YTA</td>\n",
       "      <td>cm0bft</td>\n",
       "      <td>I had a party at my house last night. I have a...</td>\n",
       "      <td>AITA for telling a friend’s friend that he cou...</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>[i, had, a, party, at, my, house, last, night,...</td>\n",
       "      <td>[i, had, a, party, at, my, house, last, night,...</td>\n",
       "      <td>[I had a party at my house last night., I have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YTA</td>\n",
       "      <td>d7omtz</td>\n",
       "      <td>Edit: I meant “unlocked” in title. Not open. \\...</td>\n",
       "      <td>AITA for monitoring my son’s shower time and m...</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>[edit, :, i, meant, “, unlocked, ”, in, title,...</td>\n",
       "      <td>[edit, i, meant, unlocked, in, title, not, ope...</td>\n",
       "      <td>[Edit: I meant “unlocked” in title., Not open....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YTA</td>\n",
       "      <td>cvlkut</td>\n",
       "      <td>So my situation is a little difficult so I tho...</td>\n",
       "      <td>WIBTA if I told a close family friend that her...</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>[so, my, situation, is, a, little, difficult, ...</td>\n",
       "      <td>[so, my, situation, is, a, little, difficult, ...</td>\n",
       "      <td>[So my situation is a little difficult so I th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  archive      id                                           selftext  \\\n",
       "0     YTA  birkjn  My wife is pregnant with our daughter. Initial...   \n",
       "1     YTA  d6cpjt  When my girlfriend and I put out advertisement...   \n",
       "2     YTA  cm0bft  I had a party at my house last night. I have a...   \n",
       "3     YTA  d7omtz  Edit: I meant “unlocked” in title. Not open. \\...   \n",
       "4     YTA  cvlkut  So my situation is a little difficult so I tho...   \n",
       "\n",
       "                                               title  \\\n",
       "0  WIBTA if I ask my pregnant wife to move out be...   \n",
       "1  AITA for throwing out my roommates non-vegan f...   \n",
       "2  AITA for telling a friend’s friend that he cou...   \n",
       "3  AITA for monitoring my son’s shower time and m...   \n",
       "4  WIBTA if I told a close family friend that her...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.reddit.com/r/AmItheAsshole/comment...   \n",
       "1  https://www.reddit.com/r/AmItheAsshole/comment...   \n",
       "2  https://www.reddit.com/r/AmItheAsshole/comment...   \n",
       "3  https://www.reddit.com/r/AmItheAsshole/comment...   \n",
       "4  https://www.reddit.com/r/AmItheAsshole/comment...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [my, wife, is, pregnant, with, our, daughter, ...   \n",
       "1  [when, my, girlfriend, and, i, put, out, adver...   \n",
       "2  [i, had, a, party, at, my, house, last, night,...   \n",
       "3  [edit, :, i, meant, “, unlocked, ”, in, title,...   \n",
       "4  [so, my, situation, is, a, little, difficult, ...   \n",
       "\n",
       "                                     tokens_no_punct  \\\n",
       "0  [my, wife, is, pregnant, with, our, daughter, ...   \n",
       "1  [when, my, girlfriend, and, i, put, out, adver...   \n",
       "2  [i, had, a, party, at, my, house, last, night,...   \n",
       "3  [edit, i, meant, unlocked, in, title, not, ope...   \n",
       "4  [so, my, situation, is, a, little, difficult, ...   \n",
       "\n",
       "                                         sent_tokens  \n",
       "0  [My wife is pregnant with our daughter., Initi...  \n",
       "1  [When my girlfriend and I put out advertisemen...  \n",
       "2  [I had a party at my house last night., I have...  \n",
       "3  [Edit: I meant “unlocked” in title., Not open....  \n",
       "4  [So my situation is a little difficult so I th...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tokenize()\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Frequencies\n",
    "Since these posts are written in the first person and talk about personal experiences, a lot of the most frequent words are pronouns, therefore the following frequency counts remove stopwords. This can be changed by replacing `True` with `False` in the no_stopwords field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequencey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like</td>\n",
       "      <td>1376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>said</td>\n",
       "      <td>1298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>would</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>told</td>\n",
       "      <td>1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>get</td>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>one</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>got</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>want</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>really</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>know</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>go</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wife</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>people</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>think</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>going</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>family</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>even</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>us</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>also</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  Frequencey\n",
       "0     like        1376\n",
       "1     said        1298\n",
       "2    would        1089\n",
       "3     told        1084\n",
       "4     time         979\n",
       "5      get         924\n",
       "6      one         883\n",
       "7      got         848\n",
       "8     want         838\n",
       "9   really         807\n",
       "10    know         753\n",
       "11      go         690\n",
       "12    wife         680\n",
       "13  people         662\n",
       "14   think         618\n",
       "15   going         611\n",
       "16  family         609\n",
       "17    even         600\n",
       "18      us         587\n",
       "19    also         583"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(get_freq_dist(archive_names.keys(), no_stopwords=True).most_common(20), columns=['Word', 'Frequencey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_a_hole</th>\n",
       "      <th>frequencey_a_hole</th>\n",
       "      <th>word</th>\n",
       "      <th>frequencey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like</td>\n",
       "      <td>691</td>\n",
       "      <td>like</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>said</td>\n",
       "      <td>677</td>\n",
       "      <td>said</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>told</td>\n",
       "      <td>534</td>\n",
       "      <td>would</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time</td>\n",
       "      <td>527</td>\n",
       "      <td>told</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>would</td>\n",
       "      <td>507</td>\n",
       "      <td>get</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>get</td>\n",
       "      <td>460</td>\n",
       "      <td>want</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>one</td>\n",
       "      <td>430</td>\n",
       "      <td>one</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>got</td>\n",
       "      <td>414</td>\n",
       "      <td>time</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>want</td>\n",
       "      <td>378</td>\n",
       "      <td>got</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>know</td>\n",
       "      <td>376</td>\n",
       "      <td>really</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>really</td>\n",
       "      <td>374</td>\n",
       "      <td>know</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>go</td>\n",
       "      <td>365</td>\n",
       "      <td>people</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wife</td>\n",
       "      <td>355</td>\n",
       "      <td>family</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>even</td>\n",
       "      <td>337</td>\n",
       "      <td>wife</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>us</td>\n",
       "      <td>328</td>\n",
       "      <td>go</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>people</td>\n",
       "      <td>319</td>\n",
       "      <td>feel</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>think</td>\n",
       "      <td>312</td>\n",
       "      <td>going</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>going</td>\n",
       "      <td>295</td>\n",
       "      <td>also</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>work</td>\n",
       "      <td>292</td>\n",
       "      <td>years</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>year</td>\n",
       "      <td>287</td>\n",
       "      <td>think</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>asked</td>\n",
       "      <td>278</td>\n",
       "      <td>asked</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>back</td>\n",
       "      <td>278</td>\n",
       "      <td>mom</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>family</td>\n",
       "      <td>275</td>\n",
       "      <td>home</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>also</td>\n",
       "      <td>269</td>\n",
       "      <td>since</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>could</td>\n",
       "      <td>265</td>\n",
       "      <td>back</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>since</td>\n",
       "      <td>264</td>\n",
       "      <td>make</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>years</td>\n",
       "      <td>263</td>\n",
       "      <td>work</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>home</td>\n",
       "      <td>259</td>\n",
       "      <td>year</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>make</td>\n",
       "      <td>257</td>\n",
       "      <td>even</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>daughter</td>\n",
       "      <td>249</td>\n",
       "      <td>kids</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>kids</td>\n",
       "      <td>248</td>\n",
       "      <td>us</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>day</td>\n",
       "      <td>240</td>\n",
       "      <td>much</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>feel</td>\n",
       "      <td>240</td>\n",
       "      <td>could</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>went</td>\n",
       "      <td>237</td>\n",
       "      <td>aita</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>aita</td>\n",
       "      <td>233</td>\n",
       "      <td>dad</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>never</td>\n",
       "      <td>232</td>\n",
       "      <td>first</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>say</td>\n",
       "      <td>228</td>\n",
       "      <td>things</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>edit</td>\n",
       "      <td>227</td>\n",
       "      <td>parents</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>friends</td>\n",
       "      <td>226</td>\n",
       "      <td>day</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>house</td>\n",
       "      <td>224</td>\n",
       "      <td>never</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>husband</td>\n",
       "      <td>224</td>\n",
       "      <td>well</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>parents</td>\n",
       "      <td>222</td>\n",
       "      <td>still</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>things</td>\n",
       "      <td>220</td>\n",
       "      <td>2</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>well</td>\n",
       "      <td>207</td>\n",
       "      <td>went</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>something</td>\n",
       "      <td>204</td>\n",
       "      <td>lot</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>asshole</td>\n",
       "      <td>204</td>\n",
       "      <td>money</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>much</td>\n",
       "      <td>200</td>\n",
       "      <td>take</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>still</td>\n",
       "      <td>199</td>\n",
       "      <td>something</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>school</td>\n",
       "      <td>198</td>\n",
       "      <td>edit</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>first</td>\n",
       "      <td>191</td>\n",
       "      <td>made</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_a_hole  frequencey_a_hole       word  frequencey\n",
       "0         like                691       like         685\n",
       "1         said                677       said         621\n",
       "2         told                534      would         582\n",
       "3         time                527       told         550\n",
       "4        would                507        get         464\n",
       "5          get                460       want         460\n",
       "6          one                430        one         453\n",
       "7          got                414       time         452\n",
       "8         want                378        got         434\n",
       "9         know                376     really         433\n",
       "10      really                374       know         377\n",
       "11          go                365     people         343\n",
       "12        wife                355     family         334\n",
       "13        even                337       wife         325\n",
       "14          us                328         go         325\n",
       "15      people                319       feel         317\n",
       "16       think                312      going         316\n",
       "17       going                295       also         314\n",
       "18        work                292      years         308\n",
       "19        year                287      think         306\n",
       "20       asked                278      asked         290\n",
       "21        back                278        mom         290\n",
       "22      family                275       home         276\n",
       "23        also                269      since         275\n",
       "24       could                265       back         272\n",
       "25       since                264       make         266\n",
       "26       years                263       work         266\n",
       "27        home                259       year         263\n",
       "28        make                257       even         263\n",
       "29    daughter                249       kids         262\n",
       "30        kids                248         us         259\n",
       "31         day                240       much         251\n",
       "32        feel                240      could         242\n",
       "33        went                237       aita         237\n",
       "34        aita                233        dad         235\n",
       "35       never                232      first         235\n",
       "36         say                228     things         234\n",
       "37        edit                227    parents         229\n",
       "38     friends                226        day         227\n",
       "39       house                224      never         220\n",
       "40     husband                224       well         212\n",
       "41     parents                222      still         209\n",
       "42      things                220          2         208\n",
       "43        well                207       went         206\n",
       "44   something                204        lot         204\n",
       "45     asshole                204      money         204\n",
       "46        much                200       take         203\n",
       "47       still                199  something         201\n",
       "48      school                198       edit         200\n",
       "49       first                191       made         200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_most_common = 50\n",
    "\n",
    "pd.DataFrame(get_freq_dist(['YTA', 'ESH'], no_stopwords=True).most_common(n_most_common),\n",
    "             columns=['word', 'frequencey']).join(\n",
    "    pd.DataFrame(get_freq_dist(['NTA', 'NAH'], no_stopwords=True).most_common(n_most_common),\n",
    "                 columns=['word', 'frequencey']), lsuffix=\"_a_hole\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-grams and Collocations\n",
    "Lets explore making bigrams and trigrams and finding collocations for this corpus.\n",
    "\n",
    "First lets look at the collocations generated from bigrams. There are several different scoring measures that can be used as is listed in one of the comments below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram_word_1_a_hole</th>\n",
       "      <th>bigram_word_2_a_hole</th>\n",
       "      <th>score_a_hole</th>\n",
       "      <th>bigram_word_1</th>\n",
       "      <th>bigram_word_2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>peanut</td>\n",
       "      <td>butter</td>\n",
       "      <td>13.993357</td>\n",
       "      <td>april</td>\n",
       "      <td>fools</td>\n",
       "      <td>14.482595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr</td>\n",
       "      <td>lastname</td>\n",
       "      <td>13.960935</td>\n",
       "      <td>baked</td>\n",
       "      <td>goods</td>\n",
       "      <td>14.260203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>passive</td>\n",
       "      <td>aggressive</td>\n",
       "      <td>13.675181</td>\n",
       "      <td>ice</td>\n",
       "      <td>cream</td>\n",
       "      <td>13.830519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fake</td>\n",
       "      <td>lashes</td>\n",
       "      <td>13.645433</td>\n",
       "      <td>imgur</td>\n",
       "      <td>com</td>\n",
       "      <td>13.575705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>miss</td>\n",
       "      <td>johnson</td>\n",
       "      <td>13.645433</td>\n",
       "      <td>tl</td>\n",
       "      <td>dr</td>\n",
       "      <td>13.482595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>y</td>\n",
       "      <td>o</td>\n",
       "      <td>13.337311</td>\n",
       "      <td>https</td>\n",
       "      <td>imgur</td>\n",
       "      <td>13.395132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tl</td>\n",
       "      <td>dr</td>\n",
       "      <td>13.282863</td>\n",
       "      <td>plant</td>\n",
       "      <td>based</td>\n",
       "      <td>13.395132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>400</td>\n",
       "      <td>calories</td>\n",
       "      <td>13.060471</td>\n",
       "      <td>cow</td>\n",
       "      <td>milk</td>\n",
       "      <td>13.197193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>blah</td>\n",
       "      <td>blah</td>\n",
       "      <td>13.008003</td>\n",
       "      <td>passive</td>\n",
       "      <td>aggressive</td>\n",
       "      <td>13.193089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>social</td>\n",
       "      <td>media</td>\n",
       "      <td>12.697901</td>\n",
       "      <td>co</td>\n",
       "      <td>worker</td>\n",
       "      <td>13.067558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ice</td>\n",
       "      <td>cream</td>\n",
       "      <td>12.666192</td>\n",
       "      <td>mixed</td>\n",
       "      <td>race</td>\n",
       "      <td>12.934159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ha</td>\n",
       "      <td>ha</td>\n",
       "      <td>12.268364</td>\n",
       "      <td>self</td>\n",
       "      <td>feeder</td>\n",
       "      <td>12.782156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>video</td>\n",
       "      <td>games</td>\n",
       "      <td>12.189754</td>\n",
       "      <td>rewards</td>\n",
       "      <td>card</td>\n",
       "      <td>12.782156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>taken</td>\n",
       "      <td>aback</td>\n",
       "      <td>12.130860</td>\n",
       "      <td>social</td>\n",
       "      <td>media</td>\n",
       "      <td>12.727708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>passport</td>\n",
       "      <td>photos</td>\n",
       "      <td>12.083554</td>\n",
       "      <td>uncle</td>\n",
       "      <td>ben</td>\n",
       "      <td>12.727708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mental</td>\n",
       "      <td>health</td>\n",
       "      <td>12.060471</td>\n",
       "      <td>aunt</td>\n",
       "      <td>tina</td>\n",
       "      <td>12.312670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gluten</td>\n",
       "      <td>free</td>\n",
       "      <td>11.898199</td>\n",
       "      <td>video</td>\n",
       "      <td>games</td>\n",
       "      <td>12.296729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fast</td>\n",
       "      <td>forward</td>\n",
       "      <td>11.709396</td>\n",
       "      <td>flu</td>\n",
       "      <td>shot</td>\n",
       "      <td>12.286198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>phd</td>\n",
       "      <td>student</td>\n",
       "      <td>11.645433</td>\n",
       "      <td>mouth</td>\n",
       "      <td>shut</td>\n",
       "      <td>12.090278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mouth</td>\n",
       "      <td>shut</td>\n",
       "      <td>11.498592</td>\n",
       "      <td>fast</td>\n",
       "      <td>forward</td>\n",
       "      <td>12.077126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>difference</td>\n",
       "      <td>between</td>\n",
       "      <td>10.770964</td>\n",
       "      <td>customer</td>\n",
       "      <td>service</td>\n",
       "      <td>12.049636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bachelor</td>\n",
       "      <td>party</td>\n",
       "      <td>10.690288</td>\n",
       "      <td>fake</td>\n",
       "      <td>accent</td>\n",
       "      <td>11.997168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>birth</td>\n",
       "      <td>control</td>\n",
       "      <td>10.666192</td>\n",
       "      <td>speaking</td>\n",
       "      <td>korean</td>\n",
       "      <td>11.952774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>watching</td>\n",
       "      <td>tv</td>\n",
       "      <td>10.443799</td>\n",
       "      <td>dress</td>\n",
       "      <td>code</td>\n",
       "      <td>11.838739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>story</td>\n",
       "      <td>short</td>\n",
       "      <td>10.379029</td>\n",
       "      <td>mental</td>\n",
       "      <td>health</td>\n",
       "      <td>11.395132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>10.329701</td>\n",
       "      <td>staff</td>\n",
       "      <td>member</td>\n",
       "      <td>11.395132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>30am</td>\n",
       "      <td>10.251154</td>\n",
       "      <td>blue</td>\n",
       "      <td>eyes</td>\n",
       "      <td>11.390895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>security</td>\n",
       "      <td>line</td>\n",
       "      <td>10.178527</td>\n",
       "      <td>title</td>\n",
       "      <td>sounds</td>\n",
       "      <td>11.386671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dick</td>\n",
       "      <td>move</td>\n",
       "      <td>9.857842</td>\n",
       "      <td>engagement</td>\n",
       "      <td>ring</td>\n",
       "      <td>11.273142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>elementary</td>\n",
       "      <td>school</td>\n",
       "      <td>9.823432</td>\n",
       "      <td>throwaway</td>\n",
       "      <td>account</td>\n",
       "      <td>10.897633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>visibly</td>\n",
       "      <td>upset</td>\n",
       "      <td>9.823432</td>\n",
       "      <td>aisle</td>\n",
       "      <td>seat</td>\n",
       "      <td>10.469133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>wedding</td>\n",
       "      <td>fund</td>\n",
       "      <td>9.823432</td>\n",
       "      <td>less</td>\n",
       "      <td>active</td>\n",
       "      <td>10.327777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>9.791010</td>\n",
       "      <td>birth</td>\n",
       "      <td>control</td>\n",
       "      <td>10.193499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>big</td>\n",
       "      <td>deal</td>\n",
       "      <td>9.575248</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>10.189814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>multiple</td>\n",
       "      <td>times</td>\n",
       "      <td>9.543895</td>\n",
       "      <td>college</td>\n",
       "      <td>fund</td>\n",
       "      <td>10.107556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>passed</td>\n",
       "      <td>away</td>\n",
       "      <td>9.472241</td>\n",
       "      <td>active</td>\n",
       "      <td>side</td>\n",
       "      <td>10.008020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>middle</td>\n",
       "      <td>class</td>\n",
       "      <td>9.465240</td>\n",
       "      <td>multiple</td>\n",
       "      <td>times</td>\n",
       "      <td>9.857617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>special</td>\n",
       "      <td>needs</td>\n",
       "      <td>9.459567</td>\n",
       "      <td>mutual</td>\n",
       "      <td>friends</td>\n",
       "      <td>9.782156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>last</td>\n",
       "      <td>straw</td>\n",
       "      <td>9.451662</td>\n",
       "      <td>story</td>\n",
       "      <td>short</td>\n",
       "      <td>9.690967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>dining</td>\n",
       "      <td>room</td>\n",
       "      <td>9.435980</td>\n",
       "      <td>looking</td>\n",
       "      <td>forward</td>\n",
       "      <td>9.670418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>foot</td>\n",
       "      <td>down</td>\n",
       "      <td>9.349500</td>\n",
       "      <td>rent</td>\n",
       "      <td>free</td>\n",
       "      <td>9.571703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>looking</td>\n",
       "      <td>forward</td>\n",
       "      <td>9.323505</td>\n",
       "      <td>long</td>\n",
       "      <td>term</td>\n",
       "      <td>9.433525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>year</td>\n",
       "      <td>olds</td>\n",
       "      <td>9.287881</td>\n",
       "      <td>gift</td>\n",
       "      <td>card</td>\n",
       "      <td>9.399686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>car</td>\n",
       "      <td>accident</td>\n",
       "      <td>9.186939</td>\n",
       "      <td>20</td>\n",
       "      <td>minutes</td>\n",
       "      <td>9.306007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>six</td>\n",
       "      <td>months</td>\n",
       "      <td>9.175113</td>\n",
       "      <td>throw</td>\n",
       "      <td>away</td>\n",
       "      <td>9.282923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>mexican</td>\n",
       "      <td>food</td>\n",
       "      <td>9.149007</td>\n",
       "      <td>both</td>\n",
       "      <td>sides</td>\n",
       "      <td>9.257629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>30</td>\n",
       "      <td>minutes</td>\n",
       "      <td>9.147348</td>\n",
       "      <td>calm</td>\n",
       "      <td>down</td>\n",
       "      <td>9.253777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>happy</td>\n",
       "      <td>holidays</td>\n",
       "      <td>9.134471</td>\n",
       "      <td>your</td>\n",
       "      <td>input</td>\n",
       "      <td>9.169712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>high</td>\n",
       "      <td>school</td>\n",
       "      <td>9.086466</td>\n",
       "      <td>passed</td>\n",
       "      <td>away</td>\n",
       "      <td>9.160932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>several</td>\n",
       "      <td>times</td>\n",
       "      <td>9.029322</td>\n",
       "      <td>shortly</td>\n",
       "      <td>after</td>\n",
       "      <td>9.160667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bigram_word_1_a_hole bigram_word_2_a_hole  score_a_hole bigram_word_1  \\\n",
       "0                peanut               butter     13.993357         april   \n",
       "1                    mr             lastname     13.960935         baked   \n",
       "2               passive           aggressive     13.675181           ice   \n",
       "3                  fake               lashes     13.645433         imgur   \n",
       "4                  miss              johnson     13.645433            tl   \n",
       "5                     y                    o     13.337311         https   \n",
       "6                    tl                   dr     13.282863         plant   \n",
       "7                   400             calories     13.060471           cow   \n",
       "8                  blah                 blah     13.008003       passive   \n",
       "9                social                media     12.697901            co   \n",
       "10                  ice                cream     12.666192         mixed   \n",
       "11                   ha                   ha     12.268364          self   \n",
       "12                video                games     12.189754       rewards   \n",
       "13                taken                aback     12.130860        social   \n",
       "14             passport               photos     12.083554         uncle   \n",
       "15               mental               health     12.060471          aunt   \n",
       "16               gluten                 free     11.898199         video   \n",
       "17                 fast              forward     11.709396           flu   \n",
       "18                  phd              student     11.645433         mouth   \n",
       "19                mouth                 shut     11.498592          fast   \n",
       "20           difference              between     10.770964      customer   \n",
       "21             bachelor                party     10.690288          fake   \n",
       "22                birth              control     10.666192      speaking   \n",
       "23             watching                   tv     10.443799         dress   \n",
       "24                story                short     10.379029        mental   \n",
       "25                   24                    7     10.329701         staff   \n",
       "26                    5                 30am     10.251154          blue   \n",
       "27             security                 line     10.178527         title   \n",
       "28                 dick                 move      9.857842    engagement   \n",
       "29           elementary               school      9.823432     throwaway   \n",
       "30              visibly                upset      9.823432         aisle   \n",
       "31              wedding                 fund      9.823432          less   \n",
       "32                   50                   50      9.791010         birth   \n",
       "33                  big                 deal      9.575248            50   \n",
       "34             multiple                times      9.543895       college   \n",
       "35               passed                 away      9.472241        active   \n",
       "36               middle                class      9.465240      multiple   \n",
       "37              special                needs      9.459567        mutual   \n",
       "38                 last                straw      9.451662         story   \n",
       "39               dining                 room      9.435980       looking   \n",
       "40                 foot                 down      9.349500          rent   \n",
       "41              looking              forward      9.323505          long   \n",
       "42                 year                 olds      9.287881          gift   \n",
       "43                  car             accident      9.186939            20   \n",
       "44                  six               months      9.175113         throw   \n",
       "45              mexican                 food      9.149007          both   \n",
       "46                   30              minutes      9.147348          calm   \n",
       "47                happy             holidays      9.134471          your   \n",
       "48                 high               school      9.086466        passed   \n",
       "49              several                times      9.029322       shortly   \n",
       "\n",
       "   bigram_word_2      score  \n",
       "0          fools  14.482595  \n",
       "1          goods  14.260203  \n",
       "2          cream  13.830519  \n",
       "3            com  13.575705  \n",
       "4             dr  13.482595  \n",
       "5          imgur  13.395132  \n",
       "6          based  13.395132  \n",
       "7           milk  13.197193  \n",
       "8     aggressive  13.193089  \n",
       "9         worker  13.067558  \n",
       "10          race  12.934159  \n",
       "11        feeder  12.782156  \n",
       "12          card  12.782156  \n",
       "13         media  12.727708  \n",
       "14           ben  12.727708  \n",
       "15          tina  12.312670  \n",
       "16         games  12.296729  \n",
       "17          shot  12.286198  \n",
       "18          shut  12.090278  \n",
       "19       forward  12.077126  \n",
       "20       service  12.049636  \n",
       "21        accent  11.997168  \n",
       "22        korean  11.952774  \n",
       "23          code  11.838739  \n",
       "24        health  11.395132  \n",
       "25        member  11.395132  \n",
       "26          eyes  11.390895  \n",
       "27        sounds  11.386671  \n",
       "28          ring  11.273142  \n",
       "29       account  10.897633  \n",
       "30          seat  10.469133  \n",
       "31        active  10.327777  \n",
       "32       control  10.193499  \n",
       "33            50  10.189814  \n",
       "34          fund  10.107556  \n",
       "35          side  10.008020  \n",
       "36         times   9.857617  \n",
       "37       friends   9.782156  \n",
       "38         short   9.690967  \n",
       "39       forward   9.670418  \n",
       "40          free   9.571703  \n",
       "41          term   9.433525  \n",
       "42          card   9.399686  \n",
       "43       minutes   9.306007  \n",
       "44          away   9.282923  \n",
       "45         sides   9.257629  \n",
       "46          down   9.253777  \n",
       "47         input   9.169712  \n",
       "48          away   9.160932  \n",
       "49         after   9.160667  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "\n",
    "# Feel free to change these values.\n",
    "n_collocs = 50\n",
    "n_freq_filter = 5\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "# Options: pmi, likelihood_ratio, chi_sq, dice, phi_sq, etc.\n",
    "scoring_measure = bigram_measures.pmi\n",
    "\n",
    "flatten = lambda l: (l[0][0], l[0][1], l[1])\n",
    "\n",
    "finder = BigramCollocationFinder.from_words(get_archive_texts(['YTA', 'ESH'], no_punctuation=True))\n",
    "finder.apply_freq_filter(n_freq_filter)\n",
    "a_hole_colloc = pd.DataFrame(list(map(flatten, finder.score_ngrams(scoring_measure))),\n",
    "                             columns=['bigram_word_1', 'bigram_word_2', 'score'])\n",
    "\n",
    "finder = BigramCollocationFinder.from_words(get_archive_texts(['NTA', 'NAH'], no_punctuation=True))\n",
    "finder.apply_freq_filter(n_freq_filter)\n",
    "colloc = pd.DataFrame(list(map(flatten, finder.score_ngrams(scoring_measure))),\n",
    "                      columns=['bigram_word_1', 'bigram_word_2', 'score'])\n",
    "\n",
    "a_hole_colloc.join(colloc, lsuffix=\"_a_hole\").head(n_collocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about trigrams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram_word_1_a_hole</th>\n",
       "      <th>trigram_word_2_a_hole</th>\n",
       "      <th>trigram_word_3_a_hole</th>\n",
       "      <th>score_a_hole</th>\n",
       "      <th>trigram_word_1</th>\n",
       "      <th>trigram_word_2</th>\n",
       "      <th>trigram_word_3</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>long</td>\n",
       "      <td>story</td>\n",
       "      <td>short</td>\n",
       "      <td>21.173606</td>\n",
       "      <td>https</td>\n",
       "      <td>imgur</td>\n",
       "      <td>com</td>\n",
       "      <td>26.970837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>on</td>\n",
       "      <td>social</td>\n",
       "      <td>media</td>\n",
       "      <td>19.204660</td>\n",
       "      <td>less</td>\n",
       "      <td>active</td>\n",
       "      <td>side</td>\n",
       "      <td>21.172299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>at</td>\n",
       "      <td>5</td>\n",
       "      <td>30am</td>\n",
       "      <td>17.767305</td>\n",
       "      <td>long</td>\n",
       "      <td>story</td>\n",
       "      <td>short</td>\n",
       "      <td>20.487062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>year</td>\n",
       "      <td>old</td>\n",
       "      <td>boy</td>\n",
       "      <td>17.366499</td>\n",
       "      <td>blake</td>\n",
       "      <td>s</td>\n",
       "      <td>ring</td>\n",
       "      <td>18.136434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my</td>\n",
       "      <td>mouth</td>\n",
       "      <td>shut</td>\n",
       "      <td>17.211599</td>\n",
       "      <td>aunt</td>\n",
       "      <td>tina</td>\n",
       "      <td>s</td>\n",
       "      <td>17.690536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>phd</td>\n",
       "      <td>student</td>\n",
       "      <td>17.142572</td>\n",
       "      <td>my</td>\n",
       "      <td>mouth</td>\n",
       "      <td>shut</td>\n",
       "      <td>17.686796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>of</td>\n",
       "      <td>ice</td>\n",
       "      <td>cream</td>\n",
       "      <td>16.945303</td>\n",
       "      <td>the</td>\n",
       "      <td>self</td>\n",
       "      <td>feeder</td>\n",
       "      <td>17.674725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>along</td>\n",
       "      <td>the</td>\n",
       "      <td>lines</td>\n",
       "      <td>16.935662</td>\n",
       "      <td>under</td>\n",
       "      <td>the</td>\n",
       "      <td>impression</td>\n",
       "      <td>16.580749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>few</td>\n",
       "      <td>days</td>\n",
       "      <td>ago</td>\n",
       "      <td>16.799013</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>minutes</td>\n",
       "      <td>16.503200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>months</td>\n",
       "      <td>ago</td>\n",
       "      <td>16.429702</td>\n",
       "      <td>reddit</td>\n",
       "      <td>aita</td>\n",
       "      <td>edit</td>\n",
       "      <td>16.373697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rant</td>\n",
       "      <td>about</td>\n",
       "      <td>how</td>\n",
       "      <td>16.423840</td>\n",
       "      <td>along</td>\n",
       "      <td>the</td>\n",
       "      <td>lines</td>\n",
       "      <td>16.325316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fast</td>\n",
       "      <td>forward</td>\n",
       "      <td>to</td>\n",
       "      <td>16.375210</td>\n",
       "      <td>couple</td>\n",
       "      <td>months</td>\n",
       "      <td>ago</td>\n",
       "      <td>16.180632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>point</td>\n",
       "      <td>of</td>\n",
       "      <td>view</td>\n",
       "      <td>16.194958</td>\n",
       "      <td>few</td>\n",
       "      <td>days</td>\n",
       "      <td>ago</td>\n",
       "      <td>16.075089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>behind</td>\n",
       "      <td>the</td>\n",
       "      <td>counter</td>\n",
       "      <td>16.068928</td>\n",
       "      <td>fast</td>\n",
       "      <td>forward</td>\n",
       "      <td>to</td>\n",
       "      <td>15.706237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pisses</td>\n",
       "      <td>me</td>\n",
       "      <td>off</td>\n",
       "      <td>15.975567</td>\n",
       "      <td>full</td>\n",
       "      <td>time</td>\n",
       "      <td>job</td>\n",
       "      <td>15.533526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>year</td>\n",
       "      <td>old</td>\n",
       "      <td>15.804621</td>\n",
       "      <td>was</td>\n",
       "      <td>looking</td>\n",
       "      <td>forward</td>\n",
       "      <td>15.501244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>see</td>\n",
       "      <td>each</td>\n",
       "      <td>other</td>\n",
       "      <td>15.688066</td>\n",
       "      <td>part</td>\n",
       "      <td>time</td>\n",
       "      <td>job</td>\n",
       "      <td>15.482900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lost</td>\n",
       "      <td>his</td>\n",
       "      <td>job</td>\n",
       "      <td>15.684051</td>\n",
       "      <td>5</td>\n",
       "      <td>year</td>\n",
       "      <td>old</td>\n",
       "      <td>15.435254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mother</td>\n",
       "      <td>in</td>\n",
       "      <td>law</td>\n",
       "      <td>15.612614</td>\n",
       "      <td>thank</td>\n",
       "      <td>you</td>\n",
       "      <td>everyone</td>\n",
       "      <td>15.413693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>year</td>\n",
       "      <td>old</td>\n",
       "      <td>15.498289</td>\n",
       "      <td>hour</td>\n",
       "      <td>or</td>\n",
       "      <td>two</td>\n",
       "      <td>15.383159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>did</td>\n",
       "      <td>anything</td>\n",
       "      <td>wrong</td>\n",
       "      <td>15.492919</td>\n",
       "      <td>for</td>\n",
       "      <td>your</td>\n",
       "      <td>input</td>\n",
       "      <td>15.339425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>edit</td>\n",
       "      <td>thank</td>\n",
       "      <td>you</td>\n",
       "      <td>15.364697</td>\n",
       "      <td>few</td>\n",
       "      <td>months</td>\n",
       "      <td>ago</td>\n",
       "      <td>15.306163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>the</td>\n",
       "      <td>security</td>\n",
       "      <td>line</td>\n",
       "      <td>15.333825</td>\n",
       "      <td>the</td>\n",
       "      <td>less</td>\n",
       "      <td>active</td>\n",
       "      <td>15.220347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>year</td>\n",
       "      <td>old</td>\n",
       "      <td>15.283083</td>\n",
       "      <td>couldn</td>\n",
       "      <td>t</td>\n",
       "      <td>afford</td>\n",
       "      <td>15.206697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ice</td>\n",
       "      <td>cream</td>\n",
       "      <td>i</td>\n",
       "      <td>15.134740</td>\n",
       "      <td>year</td>\n",
       "      <td>old</td>\n",
       "      <td>son</td>\n",
       "      <td>15.153604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>an</td>\n",
       "      <td>hour</td>\n",
       "      <td>ago</td>\n",
       "      <td>15.061078</td>\n",
       "      <td>2</td>\n",
       "      <td>months</td>\n",
       "      <td>ago</td>\n",
       "      <td>15.124049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>year</td>\n",
       "      <td>old</td>\n",
       "      <td>son</td>\n",
       "      <td>15.054419</td>\n",
       "      <td>figure</td>\n",
       "      <td>out</td>\n",
       "      <td>what</td>\n",
       "      <td>15.092074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>part</td>\n",
       "      <td>time</td>\n",
       "      <td>job</td>\n",
       "      <td>14.987707</td>\n",
       "      <td>haven</td>\n",
       "      <td>t</td>\n",
       "      <td>seen</td>\n",
       "      <td>15.051930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>year</td>\n",
       "      <td>old</td>\n",
       "      <td>daughter</td>\n",
       "      <td>14.936318</td>\n",
       "      <td>so</td>\n",
       "      <td>reddit</td>\n",
       "      <td>aita</td>\n",
       "      <td>14.970640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>two</td>\n",
       "      <td>years</td>\n",
       "      <td>ago</td>\n",
       "      <td>14.907380</td>\n",
       "      <td>few</td>\n",
       "      <td>years</td>\n",
       "      <td>ago</td>\n",
       "      <td>14.926089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>put</td>\n",
       "      <td>my</td>\n",
       "      <td>foot</td>\n",
       "      <td>14.858367</td>\n",
       "      <td>every</td>\n",
       "      <td>other</td>\n",
       "      <td>week</td>\n",
       "      <td>14.908798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>a</td>\n",
       "      <td>big</td>\n",
       "      <td>deal</td>\n",
       "      <td>14.809352</td>\n",
       "      <td>no</td>\n",
       "      <td>matter</td>\n",
       "      <td>what</td>\n",
       "      <td>14.884564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>my</td>\n",
       "      <td>foot</td>\n",
       "      <td>down</td>\n",
       "      <td>14.799474</td>\n",
       "      <td>year</td>\n",
       "      <td>old</td>\n",
       "      <td>daughter</td>\n",
       "      <td>14.824296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>had</td>\n",
       "      <td>no</td>\n",
       "      <td>idea</td>\n",
       "      <td>14.781092</td>\n",
       "      <td>wasn</td>\n",
       "      <td>t</td>\n",
       "      <td>expecting</td>\n",
       "      <td>14.811559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>as</td>\n",
       "      <td>soon</td>\n",
       "      <td>as</td>\n",
       "      <td>14.757234</td>\n",
       "      <td>looking</td>\n",
       "      <td>forward</td>\n",
       "      <td>to</td>\n",
       "      <td>14.678040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>few</td>\n",
       "      <td>years</td>\n",
       "      <td>ago</td>\n",
       "      <td>14.692980</td>\n",
       "      <td>can</td>\n",
       "      <td>t</td>\n",
       "      <td>imagine</td>\n",
       "      <td>14.656854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>sister</td>\n",
       "      <td>in</td>\n",
       "      <td>law</td>\n",
       "      <td>14.659471</td>\n",
       "      <td>sister</td>\n",
       "      <td>in</td>\n",
       "      <td>law</td>\n",
       "      <td>14.560790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>needless</td>\n",
       "      <td>to</td>\n",
       "      <td>say</td>\n",
       "      <td>14.633635</td>\n",
       "      <td>ended</td>\n",
       "      <td>up</td>\n",
       "      <td>getting</td>\n",
       "      <td>14.523657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>brother</td>\n",
       "      <td>in</td>\n",
       "      <td>law</td>\n",
       "      <td>14.492235</td>\n",
       "      <td>edit</td>\n",
       "      <td>thank</td>\n",
       "      <td>you</td>\n",
       "      <td>14.501155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>looking</td>\n",
       "      <td>forward</td>\n",
       "      <td>to</td>\n",
       "      <td>14.337242</td>\n",
       "      <td>you</td>\n",
       "      <td>guys</td>\n",
       "      <td>think</td>\n",
       "      <td>14.428192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>so</td>\n",
       "      <td>reddit</td>\n",
       "      <td>aita</td>\n",
       "      <td>14.284876</td>\n",
       "      <td>as</td>\n",
       "      <td>soon</td>\n",
       "      <td>as</td>\n",
       "      <td>14.413219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>back</td>\n",
       "      <td>and</td>\n",
       "      <td>forth</td>\n",
       "      <td>14.223916</td>\n",
       "      <td>no</td>\n",
       "      <td>idea</td>\n",
       "      <td>what</td>\n",
       "      <td>14.382976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>would</td>\n",
       "      <td>be</td>\n",
       "      <td>funny</td>\n",
       "      <td>14.194453</td>\n",
       "      <td>down</td>\n",
       "      <td>the</td>\n",
       "      <td>aisle</td>\n",
       "      <td>14.321918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>making</td>\n",
       "      <td>fun</td>\n",
       "      <td>of</td>\n",
       "      <td>14.168703</td>\n",
       "      <td>two</td>\n",
       "      <td>years</td>\n",
       "      <td>ago</td>\n",
       "      <td>14.306570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>work</td>\n",
       "      <td>full</td>\n",
       "      <td>time</td>\n",
       "      <td>14.109308</td>\n",
       "      <td>2</td>\n",
       "      <td>years</td>\n",
       "      <td>ago</td>\n",
       "      <td>14.270044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>use</td>\n",
       "      <td>the</td>\n",
       "      <td>bathroom</td>\n",
       "      <td>14.057340</td>\n",
       "      <td>put</td>\n",
       "      <td>my</td>\n",
       "      <td>foot</td>\n",
       "      <td>14.261490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>couldn</td>\n",
       "      <td>t</td>\n",
       "      <td>help</td>\n",
       "      <td>13.973041</td>\n",
       "      <td>neither</td>\n",
       "      <td>of</td>\n",
       "      <td>us</td>\n",
       "      <td>14.228304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>let</td>\n",
       "      <td>s</td>\n",
       "      <td>call</td>\n",
       "      <td>13.897732</td>\n",
       "      <td>niece</td>\n",
       "      <td>and</td>\n",
       "      <td>nephew</td>\n",
       "      <td>14.222170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>in</td>\n",
       "      <td>high</td>\n",
       "      <td>school</td>\n",
       "      <td>13.896546</td>\n",
       "      <td>my</td>\n",
       "      <td>foot</td>\n",
       "      <td>down</td>\n",
       "      <td>14.172222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>thank</td>\n",
       "      <td>you</td>\n",
       "      <td>all</td>\n",
       "      <td>13.864316</td>\n",
       "      <td>in</td>\n",
       "      <td>high</td>\n",
       "      <td>school</td>\n",
       "      <td>14.010579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trigram_word_1_a_hole trigram_word_2_a_hole trigram_word_3_a_hole  \\\n",
       "0                   long                 story                 short   \n",
       "1                     on                social                 media   \n",
       "2                     at                     5                  30am   \n",
       "3                   year                   old                   boy   \n",
       "4                     my                 mouth                  shut   \n",
       "5                      a                   phd               student   \n",
       "6                     of                   ice                 cream   \n",
       "7                  along                   the                 lines   \n",
       "8                    few                  days                   ago   \n",
       "9                      6                months                   ago   \n",
       "10                  rant                 about                   how   \n",
       "11                  fast               forward                    to   \n",
       "12                 point                    of                  view   \n",
       "13                behind                   the               counter   \n",
       "14                pisses                    me                   off   \n",
       "15                    10                  year                   old   \n",
       "16                   see                  each                 other   \n",
       "17                  lost                   his                   job   \n",
       "18                mother                    in                   law   \n",
       "19                     5                  year                   old   \n",
       "20                   did              anything                 wrong   \n",
       "21                  edit                 thank                   you   \n",
       "22                   the              security                  line   \n",
       "23                     6                  year                   old   \n",
       "24                   ice                 cream                     i   \n",
       "25                    an                  hour                   ago   \n",
       "26                  year                   old                   son   \n",
       "27                  part                  time                   job   \n",
       "28                  year                   old              daughter   \n",
       "29                   two                 years                   ago   \n",
       "30                   put                    my                  foot   \n",
       "31                     a                   big                  deal   \n",
       "32                    my                  foot                  down   \n",
       "33                   had                    no                  idea   \n",
       "34                    as                  soon                    as   \n",
       "35                   few                 years                   ago   \n",
       "36                sister                    in                   law   \n",
       "37              needless                    to                   say   \n",
       "38               brother                    in                   law   \n",
       "39               looking               forward                    to   \n",
       "40                    so                reddit                  aita   \n",
       "41                  back                   and                 forth   \n",
       "42                 would                    be                 funny   \n",
       "43                making                   fun                    of   \n",
       "44                  work                  full                  time   \n",
       "45                   use                   the              bathroom   \n",
       "46                couldn                     t                  help   \n",
       "47                   let                     s                  call   \n",
       "48                    in                  high                school   \n",
       "49                 thank                   you                   all   \n",
       "\n",
       "    score_a_hole trigram_word_1 trigram_word_2 trigram_word_3      score  \n",
       "0      21.173606          https          imgur            com  26.970837  \n",
       "1      19.204660           less         active           side  21.172299  \n",
       "2      17.767305           long          story          short  20.487062  \n",
       "3      17.366499          blake              s           ring  18.136434  \n",
       "4      17.211599           aunt           tina              s  17.690536  \n",
       "5      17.142572             my          mouth           shut  17.686796  \n",
       "6      16.945303            the           self         feeder  17.674725  \n",
       "7      16.935662          under            the     impression  16.580749  \n",
       "8      16.799013              2              3        minutes  16.503200  \n",
       "9      16.429702         reddit           aita           edit  16.373697  \n",
       "10     16.423840          along            the          lines  16.325316  \n",
       "11     16.375210         couple         months            ago  16.180632  \n",
       "12     16.194958            few           days            ago  16.075089  \n",
       "13     16.068928           fast        forward             to  15.706237  \n",
       "14     15.975567           full           time            job  15.533526  \n",
       "15     15.804621            was        looking        forward  15.501244  \n",
       "16     15.688066           part           time            job  15.482900  \n",
       "17     15.684051              5           year            old  15.435254  \n",
       "18     15.612614          thank            you       everyone  15.413693  \n",
       "19     15.498289           hour             or            two  15.383159  \n",
       "20     15.492919            for           your          input  15.339425  \n",
       "21     15.364697            few         months            ago  15.306163  \n",
       "22     15.333825            the           less         active  15.220347  \n",
       "23     15.283083         couldn              t         afford  15.206697  \n",
       "24     15.134740           year            old            son  15.153604  \n",
       "25     15.061078              2         months            ago  15.124049  \n",
       "26     15.054419         figure            out           what  15.092074  \n",
       "27     14.987707          haven              t           seen  15.051930  \n",
       "28     14.936318             so         reddit           aita  14.970640  \n",
       "29     14.907380            few          years            ago  14.926089  \n",
       "30     14.858367          every          other           week  14.908798  \n",
       "31     14.809352             no         matter           what  14.884564  \n",
       "32     14.799474           year            old       daughter  14.824296  \n",
       "33     14.781092           wasn              t      expecting  14.811559  \n",
       "34     14.757234        looking        forward             to  14.678040  \n",
       "35     14.692980            can              t        imagine  14.656854  \n",
       "36     14.659471         sister             in            law  14.560790  \n",
       "37     14.633635          ended             up        getting  14.523657  \n",
       "38     14.492235           edit          thank            you  14.501155  \n",
       "39     14.337242            you           guys          think  14.428192  \n",
       "40     14.284876             as           soon             as  14.413219  \n",
       "41     14.223916             no           idea           what  14.382976  \n",
       "42     14.194453           down            the          aisle  14.321918  \n",
       "43     14.168703            two          years            ago  14.306570  \n",
       "44     14.109308              2          years            ago  14.270044  \n",
       "45     14.057340            put             my           foot  14.261490  \n",
       "46     13.973041        neither             of             us  14.228304  \n",
       "47     13.897732          niece            and         nephew  14.222170  \n",
       "48     13.896546             my           foot           down  14.172222  \n",
       "49     13.864316             in           high         school  14.010579  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "\n",
    "# Feel free to change these values.\n",
    "n_collocs = 50\n",
    "n_freq_filter = 5\n",
    "\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "# Options: pmi, raw_freq, likelihood_ratio, chi_sq, jaccard, dice, phi_sq, etc.\n",
    "scoring_measure = trigram_measures.pmi\n",
    "\n",
    "flatten = lambda l: (l[0][0], l[0][1], l[0][2], l[1])\n",
    "\n",
    "finder = TrigramCollocationFinder.from_words(get_archive_texts(['YTA', 'ESH'], no_punctuation=True))\n",
    "finder.apply_freq_filter(n_freq_filter)\n",
    "a_hole_colloc = pd.DataFrame(list(map(flatten, finder.score_ngrams(scoring_measure)[:n_collocs])),\n",
    "                             columns=['trigram_word_1', 'trigram_word_2', 'trigram_word_3', 'score'])\n",
    "\n",
    "finder = TrigramCollocationFinder.from_words(get_archive_texts(['NTA', 'NAH'], no_punctuation=True))\n",
    "finder.apply_freq_filter(n_freq_filter)\n",
    "colloc = pd.DataFrame(list(map(flatten, finder.score_ngrams(scoring_measure)[:n_collocs])),\n",
    "                      columns=['trigram_word_1', 'trigram_word_2', 'trigram_word_3', 'score'])\n",
    "\n",
    "a_hole_colloc.join(colloc, lsuffix=\"_a_hole\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis\n",
    "NLTK provides a sentiment analysis model already called [VADER](https://github.com/cjhutto/vaderSentiment):\n",
    "\n",
    "\"VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media.\"\n",
    "\n",
    "The following are some functions to help process the text with the sentiment analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def get_average_sentiment_scores(text):\n",
    "    '''\n",
    "    Takes in a list of sentences to get the averge sentiment\n",
    "    scores for each sentence using VADER.\n",
    "    '''\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    averages = {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound': 0.0}\n",
    "    count = 0\n",
    "    for sentence in text:\n",
    "        ss = sid.polarity_scores(sentence)\n",
    "        for key, val in ss.items():\n",
    "            averages[key] += val\n",
    "        count += 1\n",
    "    for key in averages.keys():\n",
    "        averages[key] /= count\n",
    "    return averages\n",
    "\n",
    "def corpus_sentiment_scores():\n",
    "    '''\n",
    "    Updates the corpus with the average sentiment scores of each post.\n",
    "    '''\n",
    "    global corpus\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    scores = list(map(get_average_sentiment_scores, corpus['sent_tokens']))\n",
    "    corpus = corpus[corpus.columns.difference(scores[0].keys())].join(\n",
    "        pd.DataFrame(list(map(lambda d : d.values(), scores)), columns=scores[0].keys()))\n",
    "    \n",
    "def average_archive_sentiment_scores(archives):\n",
    "    '''\n",
    "    Gets the average sentiment scores for each archive and returns it\n",
    "    as a dataframe.\n",
    "    '''\n",
    "    global corpus\n",
    "    sentiment_scores = corpus.loc[\n",
    "        list(map(lambda row: row[1]['archive'] in archives,\n",
    "                 list(corpus.iterrows())))]\n",
    "    return sentiment_scores.mean(axis=0).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first put these scores into the corpus dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>archive</th>\n",
       "      <th>id</th>\n",
       "      <th>selftext</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>title</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_no_punct</th>\n",
       "      <th>url</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YTA</td>\n",
       "      <td>birkjn</td>\n",
       "      <td>My wife is pregnant with our daughter. Initial...</td>\n",
       "      <td>[My wife is pregnant with our daughter., Initi...</td>\n",
       "      <td>WIBTA if I ask my pregnant wife to move out be...</td>\n",
       "      <td>[my, wife, is, pregnant, with, our, daughter, ...</td>\n",
       "      <td>[my, wife, is, pregnant, with, our, daughter, ...</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>0.083115</td>\n",
       "      <td>0.751923</td>\n",
       "      <td>0.164962</td>\n",
       "      <td>0.096042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YTA</td>\n",
       "      <td>d6cpjt</td>\n",
       "      <td>When my girlfriend and I put out advertisement...</td>\n",
       "      <td>[When my girlfriend and I put out advertisemen...</td>\n",
       "      <td>AITA for throwing out my roommates non-vegan f...</td>\n",
       "      <td>[when, my, girlfriend, and, i, put, out, adver...</td>\n",
       "      <td>[when, my, girlfriend, and, i, put, out, adver...</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>0.073885</td>\n",
       "      <td>0.845115</td>\n",
       "      <td>0.080962</td>\n",
       "      <td>0.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YTA</td>\n",
       "      <td>cm0bft</td>\n",
       "      <td>I had a party at my house last night. I have a...</td>\n",
       "      <td>[I had a party at my house last night., I have...</td>\n",
       "      <td>AITA for telling a friend’s friend that he cou...</td>\n",
       "      <td>[i, had, a, party, at, my, house, last, night,...</td>\n",
       "      <td>[i, had, a, party, at, my, house, last, night,...</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>0.095333</td>\n",
       "      <td>0.795509</td>\n",
       "      <td>0.109176</td>\n",
       "      <td>0.069017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YTA</td>\n",
       "      <td>d7omtz</td>\n",
       "      <td>Edit: I meant “unlocked” in title. Not open. \\...</td>\n",
       "      <td>[Edit: I meant “unlocked” in title., Not open....</td>\n",
       "      <td>AITA for monitoring my son’s shower time and m...</td>\n",
       "      <td>[edit, :, i, meant, “, unlocked, ”, in, title,...</td>\n",
       "      <td>[edit, i, meant, unlocked, in, title, not, ope...</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>0.065571</td>\n",
       "      <td>0.924857</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>-0.061807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YTA</td>\n",
       "      <td>cvlkut</td>\n",
       "      <td>So my situation is a little difficult so I tho...</td>\n",
       "      <td>[So my situation is a little difficult so I th...</td>\n",
       "      <td>WIBTA if I told a close family friend that her...</td>\n",
       "      <td>[so, my, situation, is, a, little, difficult, ...</td>\n",
       "      <td>[so, my, situation, is, a, little, difficult, ...</td>\n",
       "      <td>https://www.reddit.com/r/AmItheAsshole/comment...</td>\n",
       "      <td>0.084931</td>\n",
       "      <td>0.789724</td>\n",
       "      <td>0.125276</td>\n",
       "      <td>0.095721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  archive      id                                           selftext  \\\n",
       "0     YTA  birkjn  My wife is pregnant with our daughter. Initial...   \n",
       "1     YTA  d6cpjt  When my girlfriend and I put out advertisement...   \n",
       "2     YTA  cm0bft  I had a party at my house last night. I have a...   \n",
       "3     YTA  d7omtz  Edit: I meant “unlocked” in title. Not open. \\...   \n",
       "4     YTA  cvlkut  So my situation is a little difficult so I tho...   \n",
       "\n",
       "                                         sent_tokens  \\\n",
       "0  [My wife is pregnant with our daughter., Initi...   \n",
       "1  [When my girlfriend and I put out advertisemen...   \n",
       "2  [I had a party at my house last night., I have...   \n",
       "3  [Edit: I meant “unlocked” in title., Not open....   \n",
       "4  [So my situation is a little difficult so I th...   \n",
       "\n",
       "                                               title  \\\n",
       "0  WIBTA if I ask my pregnant wife to move out be...   \n",
       "1  AITA for throwing out my roommates non-vegan f...   \n",
       "2  AITA for telling a friend’s friend that he cou...   \n",
       "3  AITA for monitoring my son’s shower time and m...   \n",
       "4  WIBTA if I told a close family friend that her...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [my, wife, is, pregnant, with, our, daughter, ...   \n",
       "1  [when, my, girlfriend, and, i, put, out, adver...   \n",
       "2  [i, had, a, party, at, my, house, last, night,...   \n",
       "3  [edit, :, i, meant, “, unlocked, ”, in, title,...   \n",
       "4  [so, my, situation, is, a, little, difficult, ...   \n",
       "\n",
       "                                     tokens_no_punct  \\\n",
       "0  [my, wife, is, pregnant, with, our, daughter, ...   \n",
       "1  [when, my, girlfriend, and, i, put, out, adver...   \n",
       "2  [i, had, a, party, at, my, house, last, night,...   \n",
       "3  [edit, i, meant, unlocked, in, title, not, ope...   \n",
       "4  [so, my, situation, is, a, little, difficult, ...   \n",
       "\n",
       "                                                 url       neg       neu  \\\n",
       "0  https://www.reddit.com/r/AmItheAsshole/comment...  0.083115  0.751923   \n",
       "1  https://www.reddit.com/r/AmItheAsshole/comment...  0.073885  0.845115   \n",
       "2  https://www.reddit.com/r/AmItheAsshole/comment...  0.095333  0.795509   \n",
       "3  https://www.reddit.com/r/AmItheAsshole/comment...  0.065571  0.924857   \n",
       "4  https://www.reddit.com/r/AmItheAsshole/comment...  0.084931  0.789724   \n",
       "\n",
       "        pos  compound  \n",
       "0  0.164962  0.096042  \n",
       "1  0.080962  0.011800  \n",
       "2  0.109176  0.069017  \n",
       "3  0.009571 -0.061807  \n",
       "4  0.125276  0.095721  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "corpus_sentiment_scores()\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do sentiment scores between the different judgemnts compare on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asshole</th>\n",
       "      <td>0.073949</td>\n",
       "      <td>0.837025</td>\n",
       "      <td>0.088843</td>\n",
       "      <td>0.042957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not the A-hole</th>\n",
       "      <td>0.081716</td>\n",
       "      <td>0.836592</td>\n",
       "      <td>0.080954</td>\n",
       "      <td>0.006575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Everyone Sucks</th>\n",
       "      <td>0.078342</td>\n",
       "      <td>0.840287</td>\n",
       "      <td>0.080346</td>\n",
       "      <td>-0.000789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No A-holes here</th>\n",
       "      <td>0.072422</td>\n",
       "      <td>0.833325</td>\n",
       "      <td>0.094126</td>\n",
       "      <td>0.054809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      neg       neu       pos  compound\n",
       "Asshole          0.073949  0.837025  0.088843  0.042957\n",
       "Not the A-hole   0.081716  0.836592  0.080954  0.006575\n",
       "Everyone Sucks   0.078342  0.840287  0.080346 -0.000789\n",
       "No A-holes here  0.072422  0.833325  0.094126  0.054809"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores = pd.concat(\n",
    "    [pd.DataFrame(average_archive_sentiment_scores([archive]), index=[0]) for archive in archive_names.keys()],\n",
    "    ignore_index=True)\n",
    "\n",
    "archive_abr = list(archive_names.keys())\n",
    "sentiment_scores.rename(index=lambda i : archive_names[archive_abr[i]], inplace=True)\n",
    "sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
